{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from load_data import *\n",
    "import numpy as np\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.FC_input = nn.Linear(input_dim, hidden_dim)\n",
    "        self.FC_input2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.FC_latent  = nn.Linear(hidden_dim, latent_dim)\n",
    "\n",
    "        \n",
    "        self.LeakyReLU = nn.LeakyReLU(0.2)\n",
    "        \n",
    "        self.training = True\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h_       = self.LeakyReLU(self.FC_input(x))\n",
    "        h_       = self.LeakyReLU(self.FC_input2(h_))\n",
    "        latent     = self.FC_latent(h_)\n",
    "\n",
    "        \n",
    "        return latent\n",
    "\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dim, output_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.FC_hidden = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.FC_hidden2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.FC_output = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "        self.LeakyReLU = nn.LeakyReLU(0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h     = self.LeakyReLU(self.FC_hidden(x))\n",
    "        h     = self.LeakyReLU(self.FC_hidden2(h))\n",
    "        \n",
    "        x_hat = self.FC_output(h)\n",
    "        return x_hat\n",
    "    \n",
    "class Model(nn.Module):\n",
    "    def __init__(self, Encoder, Decoder):\n",
    "        super(Model, self).__init__()\n",
    "        self.Encoder = Encoder\n",
    "        self.Decoder = Decoder\n",
    "        \n",
    "                \n",
    "    def forward(self, x):\n",
    "        latent = self.Encoder(x)\n",
    "        x_hat = self.Decoder(latent)\n",
    "        \n",
    "        return x_hat, latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dim = 20\n",
    "hidden_dim = 18\n",
    "latent_dim = 15\n",
    "encoder = Encoder(input_dim=x_dim, hidden_dim=hidden_dim, latent_dim=latent_dim)\n",
    "decoder = Decoder(latent_dim=latent_dim, hidden_dim = hidden_dim, output_dim =x_dim)\n",
    "\n",
    "movie_model = Model(Encoder=encoder, Decoder=decoder)\n",
    "\n",
    "\n",
    "x_dim = 3\n",
    "hidden_dim = 10\n",
    "latent_dim = 15\n",
    "encoder = Encoder(input_dim=x_dim, hidden_dim=hidden_dim, latent_dim=latent_dim)\n",
    "decoder = Decoder(latent_dim=latent_dim, hidden_dim = hidden_dim, output_dim =x_dim)\n",
    "\n",
    "user_model = Model(Encoder=encoder, Decoder=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_features = load__movies_info()\n",
    "user_movie_ratings = load_user_movie_rating()\n",
    "user_features = load_users_info()\n",
    "\n",
    "avg_score = user_movie_ratings.groupby(\"movie id\").mean()['rating'].sort_values(ascending=False)\n",
    "movie_features=pd.merge(movie_features,avg_score,on=\"movie id\")\n",
    "movie_features = movie_features.drop(['IMDb URL', 'video release date', 'release date', 'movie title', 'movie id'], axis=1)\n",
    "movies = movie_features.to_numpy()\n",
    "\n",
    "user_features[\"gender\"] = user_features[\"gender\"].astype('category')\n",
    "user_features[\"gender\"] = user_features[\"gender\"].cat.codes\n",
    "user_features[\"occupation\"] = user_features[\"occupation\"].astype('category')\n",
    "user_features[\"occupation\"] = user_features[\"occupation\"].cat.codes\n",
    "user_features = user_features.drop([\"zip code\", 'user id'], axis=1)\n",
    "users = user_features.to_numpy().astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training VAE...\n",
      "\tEpoch 1 complete! \tAverage Loss:  0.0\n",
      "\tEpoch 2 complete! \tAverage Loss:  0.0\n",
      "\tEpoch 3 complete! \tAverage Loss:  0.0\n",
      "\tEpoch 4 complete! \tAverage Loss:  0.0\n",
      "\tEpoch 5 complete! \tAverage Loss:  0.0\n",
      "Finish!!\n"
     ]
    }
   ],
   "source": [
    "loss_f = nn.MSELoss()\n",
    "optimizer = Adam(movie_model.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "print(\"Start training VAE...\")\n",
    "movie_model.train()\n",
    "\n",
    "for epoch in range(5):\n",
    "    overall_loss = 0\n",
    "    \n",
    "    for i in range(movies.shape[0]):\n",
    "\n",
    "        x = torch.from_numpy(movies[i].reshape(1, -1)).float()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x_recon, _ = movie_model(x)\n",
    "        loss = loss_f(x_recon, x)\n",
    "        \n",
    "#         overall_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(\"\\tEpoch\", epoch + 1, \"complete!\", \"\\tAverage Loss: \", overall_loss / (movies.shape[0]))\n",
    "\n",
    "print(\"Finish!!\")\n",
    "\n",
    "torch.save(movie_model.state_dict(), 'movie_vae.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training VAE...\n",
      "\tEpoch 1 complete! \tAverage Loss:  0.0\n",
      "\tEpoch 2 complete! \tAverage Loss:  0.0\n",
      "\tEpoch 3 complete! \tAverage Loss:  0.0\n",
      "\tEpoch 4 complete! \tAverage Loss:  0.0\n",
      "\tEpoch 5 complete! \tAverage Loss:  0.0\n",
      "Finish!!\n"
     ]
    }
   ],
   "source": [
    "loss_f = nn.MSELoss()\n",
    "optimizer = Adam(user_model.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "print(\"Start training VAE...\")\n",
    "movie_model.train()\n",
    "\n",
    "for epoch in range(5):\n",
    "    overall_loss = 0\n",
    "    \n",
    "    for i in range(users.shape[0]):\n",
    "\n",
    "        x = torch.from_numpy(users[i].reshape(1, -1)).float()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x_recon, _ = user_model(x)\n",
    "        loss = loss_f(x_recon, x)\n",
    "        \n",
    "#         overall_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(\"\\tEpoch\", epoch + 1, \"complete!\", \"\\tAverage Loss: \", overall_loss / (users.shape[0]))\n",
    "\n",
    "print(\"Finish!!\")\n",
    "\n",
    "torch.save(user_model.state_dict(), 'user_vae.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1682, 20)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DRL",
   "language": "python",
   "name": "drl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
